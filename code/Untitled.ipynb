{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19697a38-31ce-4dfc-99d0-5f43e15a8cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c2dde5e-031b-4e8d-9e7c-590ef9e44a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import timm\n",
    "from timm import optim, scheduler\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from sklearn import metrics as skmet\n",
    "import os\n",
    "import json\n",
    "\n",
    "import transforms as my_transforms\n",
    "from dataset import EchoNetFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5acac065-f89a-4f58-8845-ebfba72e8640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: 1315340\n",
      "Validation data size: 228836\n",
      "----------------------------------------\n",
      "Epoch 1 of 10:\n",
      "Unfreezing model encoder.\n",
      "Training:                                                                                           \n",
      "\tMSE loss = 0.163\n",
      "Test:\n",
      "\tMSE loss = 0.119\n",
      "\tEF metrics:\n",
      "\t\tr2 = 0.170\n",
      "\t\tmae = 0.087\n",
      "\t\trmse = 0.110\n",
      "\tESV metrics:\n",
      "\t\tr2 = 0.431\n",
      "\t\tmae = 0.138\n",
      "\t\trmse = 0.209\n",
      "\tEDV metrics:\n",
      "\t\tr2 = 0.390\n",
      "\t\tmae = 0.203\n",
      "\t\trmse = 0.276\n",
      "----------------------------------------\n",
      "Epoch 2 of 10:\n",
      "Training:                                                                                           \n",
      "\tMSE loss = 0.110\n",
      "Test:\n",
      "\tMSE loss = 0.099\n",
      "\tEF metrics:\n",
      "\t\tr2 = 0.313\n",
      "\t\tmae = 0.077\n",
      "\t\trmse = 0.100\n",
      "\tESV metrics:\n",
      "\t\tr2 = 0.546\n",
      "\t\tmae = 0.121\n",
      "\t\trmse = 0.186\n",
      "\tEDV metrics:\n",
      "\t\tr2 = 0.484\n",
      "\t\tmae = 0.187\n",
      "\t\trmse = 0.253\n",
      "----------------------------------------\n",
      "Epoch 3 of 10:\n",
      "Training:                                                                                           \n",
      "\tMSE loss = 0.093\n",
      "Test:\n",
      "\tMSE loss = 0.093\n",
      "\tEF metrics:\n",
      "\t\tr2 = 0.340\n",
      "\t\tmae = 0.075\n",
      "\t\trmse = 0.098\n",
      "\tESV metrics:\n",
      "\t\tr2 = 0.573\n",
      "\t\tmae = 0.118\n",
      "\t\trmse = 0.181\n",
      "\tEDV metrics:\n",
      "\t\tr2 = 0.512\n",
      "\t\tmae = 0.182\n",
      "\t\trmse = 0.246\n",
      "----------------------------------------\n",
      "Epoch 4 of 10:\n",
      "Training:                                                                                           \n",
      "\tMSE loss = 0.081\n",
      "Test:\n",
      "\tMSE loss = 0.091\n",
      "\tEF metrics:\n",
      "\t\tr2 = 0.380\n",
      "\t\tmae = 0.071\n",
      "\t\trmse = 0.095\n",
      "\tESV metrics:\n",
      "\t\tr2 = 0.584\n",
      "\t\tmae = 0.113\n",
      "\t\trmse = 0.178\n",
      "\tEDV metrics:\n",
      "\t\tr2 = 0.522\n",
      "\t\tmae = 0.178\n",
      "\t\trmse = 0.244\n",
      "----------------------------------------\n",
      "Epoch 5 of 10:\n",
      "Training:                                                                                           \n",
      "\tMSE loss = 0.073\n",
      "Test:\n",
      "\tMSE loss = 0.090\n",
      "\tEF metrics:\n",
      "\t\tr2 = 0.380\n",
      "\t\tmae = 0.071\n",
      "\t\trmse = 0.095\n",
      "\tESV metrics:\n",
      "\t\tr2 = 0.585\n",
      "\t\tmae = 0.111\n",
      "\t\trmse = 0.178\n",
      "\tEDV metrics:\n",
      "\t\tr2 = 0.534\n",
      "\t\tmae = 0.175\n",
      "\t\trmse = 0.241\n",
      "----------------------------------------\n",
      "Epoch 6 of 10:\n",
      "Training:                                                                                           \n",
      "\tMSE loss = 0.066\n",
      "Test:\n",
      "\tMSE loss = 0.087\n",
      "\tEF metrics:\n",
      "\t\tr2 = 0.386\n",
      "\t\tmae = 0.071\n",
      "\t\trmse = 0.095\n",
      "\tESV metrics:\n",
      "\t\tr2 = 0.600\n",
      "\t\tmae = 0.110\n",
      "\t\trmse = 0.175\n",
      "\tEDV metrics:\n",
      "\t\tr2 = 0.544\n",
      "\t\tmae = 0.174\n",
      "\t\trmse = 0.238\n",
      "----------------------------------------\n",
      "Epoch 7 of 10:\n",
      "Training:                                                                                           \n",
      "\tMSE loss = 0.061\n",
      "Test:\n",
      "\tMSE loss = 0.089\n",
      "\tEF metrics:\n",
      "\t\tr2 = 0.391\n",
      "\t\tmae = 0.070\n",
      "\t\trmse = 0.094\n",
      "\tESV metrics:\n",
      "\t\tr2 = 0.591\n",
      "\t\tmae = 0.111\n",
      "\t\trmse = 0.177\n",
      "\tEDV metrics:\n",
      "\t\tr2 = 0.539\n",
      "\t\tmae = 0.174\n",
      "\t\trmse = 0.240\n",
      "----------------------------------------\n",
      "Epoch 8 of 10:\n",
      "Training:                                                                                           \n",
      "\tMSE loss = 0.056\n",
      "Test:\n",
      "\tMSE loss = 0.087\n",
      "\tEF metrics:\n",
      "\t\tr2 = 0.392\n",
      "\t\tmae = 0.070\n",
      "\t\trmse = 0.094\n",
      "\tESV metrics:\n",
      "\t\tr2 = 0.601\n",
      "\t\tmae = 0.110\n",
      "\t\trmse = 0.175\n",
      "\tEDV metrics:\n",
      "\t\tr2 = 0.543\n",
      "\t\tmae = 0.173\n",
      "\t\trmse = 0.239\n",
      "----------------------------------------\n",
      "Epoch 9 of 10:\n",
      "Training:                                                                                           \n",
      "\tMSE loss = 0.052\n",
      "Test:\n",
      "\tMSE loss = 0.087\n",
      "\tEF metrics:\n",
      "\t\tr2 = 0.390\n",
      "\t\tmae = 0.070\n",
      "\t\trmse = 0.094\n",
      "\tESV metrics:\n",
      "\t\tr2 = 0.603\n",
      "\t\tmae = 0.110\n",
      "\t\trmse = 0.174\n",
      "\tEDV metrics:\n",
      "\t\tr2 = 0.545\n",
      "\t\tmae = 0.173\n",
      "\t\trmse = 0.238\n",
      "----------------------------------------\n",
      "Epoch 10 of 10:\n",
      "Training:                                                                                           \n",
      "\tMSE loss = 0.049\n",
      "Test:\n",
      "\tMSE loss = 0.089\n",
      "\tEF metrics:\n",
      "\t\tr2 = 0.393\n",
      "\t\tmae = 0.070\n",
      "\t\trmse = 0.094\n",
      "\tESV metrics:\n",
      "\t\tr2 = 0.588\n",
      "\t\tmae = 0.110\n",
      "\t\trmse = 0.178\n",
      "\tEDV metrics:\n",
      "\t\tr2 = 0.536\n",
      "\t\tmae = 0.174\n",
      "\t\trmse = 0.240\n"
     ]
    }
   ],
   "source": [
    "def train_one_epoch(model, optimizer, train_dataloader, loss_function, device):\n",
    "    model.train()\n",
    "\n",
    "    num_steps_per_epoch = len(train_dataloader)\n",
    "\n",
    "    losses = []\n",
    "    for ix, batch in enumerate(train_dataloader):\n",
    "        inputs = batch['img'].to(device)\n",
    "        esv_true = batch['ESV'].to(device).type(torch.float32)\n",
    "        edv_true = batch['EDV'].to(device).type(torch.float32)\n",
    "        outputs = model(inputs)\n",
    "        esv_pred = outputs[:,0] \n",
    "        edv_pred = outputs[:,1]\n",
    "        loss_esv = loss_function(esv_pred, esv_true)\n",
    "        loss_edv = loss_function(edv_pred, edv_true)\n",
    "        loss = loss_esv + loss_edv\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        losses.append(loss.detach().item())\n",
    "        print(f\"\\tBatch {ix+1} of {num_steps_per_epoch}. Loss={loss.detach().item():0.3f}\", end='\\r')\n",
    "    \n",
    "    print(' '*100, end='\\r')\n",
    "        \n",
    "    return np.mean(losses)    \n",
    "            \n",
    "def evaluate(model, val_dataloader, loss_function, device):\n",
    "    model.eval()\n",
    "\n",
    "    num_steps_per_epoch = len(val_dataloader)\n",
    "\n",
    "    esv_true_ls = []\n",
    "    edv_true_ls = []\n",
    "    esv_pred_ls = []\n",
    "    edv_pred_ls = []\n",
    "    losses = []\n",
    "    for ix, batch in enumerate(val_dataloader):\n",
    "        inputs = batch['img'].to(device)\n",
    "        esv_true = batch['ESV'].to(device).type(torch.float32)\n",
    "        edv_true = batch['EDV'].to(device).type(torch.float32)\n",
    "        esv_true_ls.append(esv_true.cpu().numpy())\n",
    "        edv_true_ls.append(edv_true.cpu().numpy())\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "            esv_pred = outputs[:,0] \n",
    "            edv_pred = outputs[:,1]\n",
    "            esv_pred_ls.append(esv_pred.cpu().numpy())\n",
    "            edv_pred_ls.append(edv_pred.cpu().numpy())\n",
    "            \n",
    "            loss_esv = loss_function(esv_pred, esv_true)\n",
    "            loss_edv = loss_function(edv_pred, edv_true)\n",
    "            loss = loss_esv + loss_edv\n",
    "            \n",
    "        losses.append(loss.detach().item())\n",
    "        \n",
    "    esv_true_ar = np.concatenate(esv_true_ls)\n",
    "    esv_pred_ar = np.concatenate(esv_pred_ls)\n",
    "    edv_true_ar = np.concatenate(edv_true_ls)\n",
    "    edv_pred_ar = np.concatenate(edv_pred_ls)\n",
    "    ef_true_ar = (edv_true_ar - esv_true_ar) / edv_true_ar\n",
    "    ef_pred_ar = (edv_pred_ar - esv_pred_ar) / edv_pred_ar\n",
    "    metrics_esv = compute_metrics(esv_true_ar, esv_pred_ar)\n",
    "    metrics_edv = compute_metrics(edv_true_ar, edv_pred_ar)\n",
    "    metrics_ef = compute_metrics(ef_true_ar, ef_pred_ar)\n",
    "    \n",
    "    return np.mean(losses), metrics_esv, metrics_edv, metrics_ef\n",
    "\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    mets = dict()\n",
    "    \n",
    "    mets['r2'] = skmet.r2_score(y_true, y_pred)\n",
    "    mets['mae'] = skmet.mean_absolute_error(y_true, y_pred)\n",
    "    mets['rmse'] = np.sqrt(skmet.mean_squared_error(y_true, y_pred))\n",
    "    \n",
    "    return mets\n",
    "\n",
    "def main(cfg):\n",
    "    os.makedirs(cfg['artifact_folder'], exist_ok=True)\n",
    "\n",
    "    # save the config file to the artifact folder\n",
    "    with open(cfg['artifact_folder'] + '/config.json', 'w') as f: \n",
    "        json.dump(cfg, f, indent=4)\n",
    "\n",
    "    device = torch.device(cfg['device'])\n",
    "\n",
    "    # transforms\n",
    "    tfms = my_transforms.ImageTransforms(cfg['res'])\n",
    "    tfms_train = tfms.get_transforms(cfg['transforms']['train'])\n",
    "    tfms_test = tfms.get_transforms(cfg['transforms']['test'])\n",
    "\n",
    "    # load data\n",
    "    df_train = pd.read_csv(cfg['in_paths']['train'])\n",
    "    df_val = pd.read_csv(cfg['in_paths']['val'])\n",
    "    df_frames = pd.read_csv(cfg['in_paths']['frames'])\n",
    "    \n",
    "    # create datasets\n",
    "    d_train = EchoNetFrames(df_train, df_frames, transforms = tfms_train, downsample_frac=cfg['downsample_frac'])\n",
    "    dl_train = DataLoader(d_train, batch_size=cfg['bs_train'], num_workers=cfg['num_workers'], shuffle=True)\n",
    "\n",
    "    d_val = EchoNetFrames(df_val, df_frames, transforms = tfms_test, downsample_frac=cfg['downsample_frac'])\n",
    "    dl_val= DataLoader(d_val, batch_size=cfg['bs_val'], num_workers=cfg['num_workers'])\n",
    "\n",
    "    print(\"Train data size:\", len(d_train))\n",
    "    print(\"Validation data size:\", len(d_val))\n",
    "\n",
    "    # classifier network\n",
    "    m = timm.create_model(cfg['model'], pretrained=cfg['pretrained'], num_classes=2, in_chans=3, drop_rate=cfg['dropout'])\n",
    "    m.to(device)\n",
    "\n",
    "    # freeze model weights\n",
    "    # don't freeze classifier or first conv/bn\n",
    "    for layer in list(m.children())[2:-1]:\n",
    "        for p in layer.parameters():\n",
    "            p.requires_grad = False\n",
    "    is_frozen=True\n",
    "\n",
    "    # fit\n",
    "    optimizer = optim.AdamP(m.parameters(), lr=cfg['lr'], weight_decay=cfg['weight_decay'])\n",
    "    scheduler = ExponentialLR(optimizer, gamma=cfg['lr_gamma'])\n",
    "    loss_function = torch.functional.F.mse_loss\n",
    "\n",
    "    train_loss_ls = []\n",
    "    test_loss_ls = []\n",
    "\n",
    "    best_test_loss = 1000\n",
    "    for epoch in range(cfg['num_epochs']):\n",
    "        print(\"-\"*40)\n",
    "        print(f\"Epoch {epoch+1} of {cfg['num_epochs']}:\")\n",
    "\n",
    "        # maybe unfreeze \n",
    "        if epoch >= cfg['unfreeze_after_n'] and is_frozen:\n",
    "            print(\"Unfreezing model encoder.\")\n",
    "            is_frozen=False\n",
    "            for p in m.parameters():\n",
    "                p.requires_grad = True\n",
    "\n",
    "            for g in optimizer.param_groups:\n",
    "                g['lr'] = cfg['lr_unfrozen']\n",
    "\n",
    "        # train for a single epoch\n",
    "        train_loss = train_one_epoch(m, optimizer, dl_train, loss_function, device)\n",
    "        train_loss_ls.append(train_loss)\n",
    "        print(f\"Training:\")\n",
    "        print(f\"\\tMSE loss = {train_loss:0.3f}\")       \n",
    "\n",
    "        # evaluate\n",
    "        test_loss, met_esv, met_edv, met_ef = evaluate(m, dl_val, loss_function, device)\n",
    "        test_loss_ls.append(test_loss)\n",
    "        print(f\"Test:\")\n",
    "        print(f\"\\tMSE loss = {test_loss:0.3f}\")\n",
    "        print(f\"\\tEF metrics:\")\n",
    "        for k, v in met_ef.items():\n",
    "            print(f\"\\t\\t{k} = {v:0.3f}\")\n",
    "        print(f\"\\tESV metrics:\")\n",
    "        for k, v in met_esv.items():\n",
    "            print(f\"\\t\\t{k} = {v:0.3f}\")\n",
    "        print(f\"\\tEDV metrics:\")\n",
    "        for k, v in met_edv.items():\n",
    "            print(f\"\\t\\t{k} = {v:0.3f}\")\n",
    "\n",
    "        if test_loss < best_test_loss:\n",
    "            torch.save(m.state_dict(), f\"{cfg['artifact_folder']}/model_checkpoint.ckpt\")\n",
    "            best_test_loss = test_loss\n",
    "\n",
    "        scheduler.step()\n",
    "        \n",
    "if __name__=='__main__':\n",
    "    from config import config_pretrain_echonet as cfg\n",
    "    import argparse\n",
    "    # parser = argparse.ArgumentParser('Pretrain frame classifier')\n",
    "    # parser.add_argument('--artifact-folder', type=str, metavar='DIR', required=True,\n",
    "    #                     help='path to artifact folder')\n",
    "    # args = parser.parse_args()\n",
    "    \n",
    "    cfg['artifact_folder'] = '/zfs/wficai/pda/model_run_artifacts/echonet_pretrain' #args.artifact_folder\n",
    "    main(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b274c7-1fce-4697-b24d-8af0a19a924b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PDA",
   "language": "python",
   "name": "pda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
