{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daaa341c-0948-46ae-8454-8e47c62cf06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db27084b-c3c0-4e7a-bc00-dab2262def34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from torch.utils.data import DataLoader\n",
    "import timm\n",
    "from timm import optim, scheduler\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics as skmet\n",
    "from jupyterplot import ProgressPlot\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "\n",
    "import transforms as my_transforms\n",
    "%aimport dataset\n",
    "from models import MultiTaskFrameClassifier\n",
    "ImageData = dataset.ImageData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7af05b89-c3b2-4d84-8f4a-ab907f26fe8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact_folder = '/zfs/wficai/pda/model_run_artifacts/20220818_multitask_224x224'\n",
    "# artifact_folder = '/zfs/wficai/pda/model_run_artifacts/20220818_all_224x224'\n",
    "# artifact_folder = '/zfs/wficai/pda/model_run_artifacts/20220818_justcolor_224x224'\n",
    "os.makedirs(artifact_folder, exist_ok=True)\n",
    "\n",
    "datestamp = '20220901'\n",
    "\n",
    "# Note: all configurations are packaged as dict for easy saving\n",
    "cfg = dict(\n",
    "    sanity_check = False,\n",
    "    sanity_check_frac = 0.1,\n",
    "    mode_filter =  ['2d', 'color', 'color_compare'],\n",
    "    view_filter = ['pdaView', 'pdaRelatedView', 'nonPDAView'],\n",
    "    test_frac = 0.25,\n",
    "    bs_train = 256,  # batch size for training\n",
    "    bs_test = 500,  # batch size for testing\n",
    "    num_workers = 10,  # number of parallel data loading workers\n",
    "    res = 224, # pixel size along height and width\n",
    "    device = 'cuda:0',\n",
    "    model = 'resnet50d',\n",
    "    weights = {'type': 1.0, 'mode': 0.1, 'view': 0.1},\n",
    "    num_epochs=12,\n",
    "    lr = 0.001,\n",
    "    lr_gamma = 0.92,\n",
    "    dropout = 0.3,\n",
    "    weight_decay = 0.001,\n",
    "    pretrained=True,\n",
    "    unfreeze_after_n=2,\n",
    "    lr_unfrozen = 0.00001,\n",
    "    in_paths = dict(\n",
    "        frame = f'/zfs/wficai/pda/model_data/{datestamp}_frame.csv',\n",
    "        video = f'/zfs/wficai/pda/model_data/{datestamp}_video.csv',\n",
    "        study = f'/zfs/wficai/pda/model_data/{datestamp}_study.csv',\n",
    "        patient_study = f'/zfs/wficai/pda/model_data/{datestamp}_patient_study.csv',\n",
    "        patient = f'/zfs/wficai/pda/model_data/{datestamp}_patient.csv'\n",
    "    ),\n",
    "    out_paths = dict(\n",
    "        train = 'train.csv',\n",
    "        test = 'test.csv'\n",
    "    ),\n",
    "    transforms = dict(\n",
    "        train = 'train',\n",
    "        test = 'test'\n",
    "    )\n",
    ")\n",
    "\n",
    "with open(artifact_folder + '/config.json', 'w') as f: \n",
    "    json.dump(cfg, f, indent=4)\n",
    "    \n",
    "# put all config variables in scope to avoid the need to laboriously index cfg\n",
    "for k, v in cfg.items():\n",
    "    v = f\"'{v}'\" if type(v)==str else v\n",
    "    exec(f\"{k}={v}\")\n",
    "del cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40792ac2-3896-4333-be17-a0c151423d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bd114bb-8654-42da-875d-0bb19d74fb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_frame = pd.read_csv(in_paths['frame'])\n",
    "df_video = pd.read_csv(in_paths['video'])\n",
    "df_study = pd.read_csv(in_paths['study'])\n",
    "df_patient_study = pd.read_csv(in_paths['patient_study'])\n",
    "df_patient = pd.read_csv(in_paths['patient'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50e7023d-8c68-46a5-b3fc-b3e8072550ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nopda    76\n",
       "pda      45\n",
       "Name: patient_type, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_study.patient_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3c9d4cc-b931-4e85-bb12-ec828a9ebb2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((141410, 14), (55176, 14))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_patient_train, df_patient_test = train_test_split(df_patient, test_size=test_frac, shuffle=True)\n",
    "df_train = df_patient_train.merge(df_patient_study).merge(df_study, on=['patient_type', 'study']).merge(df_video, on=['patient_type', 'study']).merge(df_frame, on=['patient_type', 'external_id'])\n",
    "df_test = df_patient_test.merge(df_patient_study).merge(df_study, on=['patient_type', 'study']).merge(df_video, on=['patient_type', 'study']).merge(df_frame, on=['patient_type', 'external_id'])\n",
    "\n",
    "\n",
    "df_train.to_csv(f\"{artifact_folder}/{out_paths['train']}\", index=False)\n",
    "df_test.to_csv(f\"{artifact_folder}/{out_paths['test']}\", index=False)\n",
    "\n",
    "if sanity_check: \n",
    "    df_train = df_train.sample(frac=sanity_check_frac)\n",
    "    df_test = df_test.sample(frac=sanity_check_frac)\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ab5c0db-7213-43dd-b85f-53ad4596d8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All disjoint checks passed\n"
     ]
    }
   ],
   "source": [
    "# ensure that patients are disjoint\n",
    "train_patient = set(df_train.patient_id)\n",
    "test_patient = set(df_test.patient_id)\n",
    "assert train_patient.isdisjoint(test_patient), 'Set of train patients and set of test patients are not disjoint!'\n",
    "\n",
    "# ensure that studies are disjoint\n",
    "train_study = set(df_train.study + df_train.patient_type)\n",
    "test_study = set(df_test.study + df_test.patient_type)\n",
    "assert train_study.isdisjoint(test_study), 'Set of train studies and set of test studies are not disjoint!'\n",
    "\n",
    "# ensure that videos are disjoint\n",
    "train_vids = set(df_train.external_id + df_train.patient_type)\n",
    "test_vids = set(df_test.external_id + df_test.patient_type)\n",
    "assert train_vids.isdisjoint(test_vids), 'Set of train videos and set of test videos are not disjoint!'\n",
    "\n",
    "# ensure that frames are disjoint\n",
    "train_frames = set(df_train.png_path)\n",
    "test_frames = set(df_test.png_path)\n",
    "assert train_frames.isdisjoint(test_frames), 'Set of train frames and set of test frames are not disjoint!'\n",
    "\n",
    "print(\"All disjoint checks passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c46042a3-6018-4497-ae4a-a40317232777",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = my_transforms.ImageTransforms(res)\n",
    "tfms_train = tfms.get_transforms(transforms['train'])\n",
    "tfms_test = tfms.get_transforms(transforms['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19561d1-c7f0-4131-bb27-2bb32f19141a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size after filtering: 141410\n",
      "Test data size after filtering: 55176\n"
     ]
    }
   ],
   "source": [
    "# create datasets\n",
    "d_train = ImageData(df_train, transforms = tfms_train, mode_filter = mode_filter, view_filter = view_filter)\n",
    "dl_train = DataLoader(d_train, batch_size=bs_train, num_workers=num_workers, shuffle=True)\n",
    "\n",
    "d_test = ImageData(df_test, transforms = tfms_test, mode_filter = mode_filter, view_filter = view_filter)\n",
    "dl_test = DataLoader(d_test, batch_size=bs_test, num_workers=num_workers)\n",
    "\n",
    "print(\"Train data size after filtering:\", len(d_train))\n",
    "print(\"Test data size after filtering:\", len(d_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4430e70-798a-413d-917c-9bce0caa89bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch = next(iter(dl_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2df49f61-e396-46e1-9af9-9fa212099aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_dataloader, loss_function, device):\n",
    "    model.train()\n",
    "\n",
    "    num_steps_per_epoch = len(train_dataloader)\n",
    "\n",
    "    losses = []\n",
    "    for ix, batch in enumerate(train_dataloader):\n",
    "        inputs = batch['img'].to(device)\n",
    "        targets = {k: batch[k].to(device).type(torch.float32) for k in ['trg_type', 'trg_mode', 'trg_view']}\n",
    "        \n",
    "        predictions = model(inputs)\n",
    "\n",
    "        loss = loss_function(predictions, targets, weights)\n",
    "        loss['total'].backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        losses.append({k: v.detach().item() for k, v in loss.items()})\n",
    "        print(f\"\\tBatch {ix+1} of {num_steps_per_epoch}. Loss={loss['total'].detach().item():0.3f}\", end='\\r')\n",
    "    \n",
    "    print(' '*100, end='\\r')\n",
    "        \n",
    "    losses = pd.DataFrame(losses).mean()\n",
    "    return losses\n",
    "            \n",
    "def evaluate(model, test_dataloader, loss_function, device):\n",
    "    model.eval()\n",
    "\n",
    "    num_steps_per_epoch = len(test_dataloader)\n",
    "\n",
    "    patient_ls = []\n",
    "    target_ls = []\n",
    "    output_ls = []\n",
    "    losses = []\n",
    "    for ix, batch in enumerate(test_dataloader):\n",
    "        inputs = batch['img'].to(device)\n",
    "        targets = {k: batch[k].to(device).type(torch.float32) for k in ['trg_type', 'trg_mode', 'trg_view']}\n",
    "        target_ls.append(targets)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            predictions = model(inputs)\n",
    "            output_ls.append(predictions)\n",
    "            loss = loss_function(predictions, targets, weights)\n",
    "            \n",
    "        losses.append(loss)\n",
    "        \n",
    "    #compute metrics\n",
    "    \n",
    "    metrics = compute_metrics(target_ls, output_ls)\n",
    "    \n",
    "    #average loss\n",
    "    avg_losses = pd.DataFrame(losses).mean()\n",
    "    \n",
    "    return avg_losses, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d0192d3-c53f-4e8e-bf7b-656a2270813c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(target_ls, output_ls):\n",
    "    y_true = torch.concat([trg['trg_type'] for trg in target_ls]).detach().cpu().numpy()\n",
    "    y_pred = torch.concat([out['type'] for out in output_ls]).detach().cpu().numpy().squeeze()\n",
    "    \n",
    "    # filter out nonPDAViews and 2d images when computing type prediction metrics\n",
    "    trg_mode = torch.concat([trg['trg_mode'] for trg in target_ls]).detach().cpu().numpy()\n",
    "    trg_view = torch.concat([trg['trg_view'] for trg in target_ls]).detach().cpu().numpy()\n",
    "    type_filter = (trg_view==0) | (trg_mode==0)\n",
    "    y_true = y_true[~type_filter]\n",
    "    y_pred = y_pred[~type_filter]\n",
    "    \n",
    "    y_pred = 1/(1+np.exp(-y_pred))\n",
    "    y_pred_cls = (y_pred>0.5).astype(int)\n",
    "    \n",
    "    mets = dict()    \n",
    "    mets['roc_auc'] = skmet.roc_auc_score(y_true, y_pred)\n",
    "    mets['average_precision'] = skmet.average_precision_score(y_true, y_pred)\n",
    "    mets['accuracy'] = skmet.accuracy_score(y_true, y_pred_cls)\n",
    "    mets['sensitivity'] = skmet.recall_score(y_true, y_pred_cls)\n",
    "    mets['specificity'] = skmet.recall_score(y_true, y_pred_cls, pos_label=0)\n",
    "    \n",
    "    return mets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f59b10c2-a6ec-43c1-9b24-82e56d096ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "is_encoder_frozen = True if unfreeze_after_n>0 else False    \n",
    "encoder = timm.create_model(model, pretrained=pretrained, num_classes=1, in_chans=3, drop_rate=dropout)\n",
    "clf = MultiTaskFrameClassifier(encoder, encoder_frozen=is_encoder_frozen).to(device)\n",
    "loss_func = MultiTaskFrameClassifier.multi_task_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0411402-8561-4909-a4eb-da69f9fd4f2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total': tensor(0.3835, device='cuda:0', grad_fn=<MeanBackward1>),\n",
       " 'type': tensor(0.1601, device='cuda:0', grad_fn=<MeanBackward1>),\n",
       " 'mode': tensor(1.0962, device='cuda:0', grad_fn=<MeanBackward1>),\n",
       " 'view': tensor(1.1381, device='cuda:0', grad_fn=<MeanBackward1>)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = clf(test_batch['img'].to(device))\n",
    "targets = {k: test_batch[k].to(device) for k in ['trg_type', 'trg_mode', 'trg_view']}\n",
    "loss_dict = loss_func(outputs, targets, weights=weights)\n",
    "loss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6fb49fc-332d-440d-905e-e48a6593c670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(total    0.391153\n",
       " type     0.166150\n",
       " mode     1.101292\n",
       " view     1.148740\n",
       " dtype: float64,\n",
       " {'roc_auc': 0.6400613546606579,\n",
       "  'average_precision': 0.9036726764051608,\n",
       "  'accuracy': 0.8559327686253585,\n",
       "  'sensitivity': 0.9828562563028469,\n",
       "  'specificity': 0.07754519505233111})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(clf, dl_test, loss_func, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43063e9b-b9ae-494a-91b2-3d0b3f280b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Epoch 1 of 12:\n",
      "Training:                                                                                           \n",
      "\tcross_entropy:\n",
      "\t\ttotal = 0.233\n",
      "\t\ttype = 0.121\n",
      "\t\tmode = 0.375\n",
      "\t\tview = 0.745\n",
      "Test:\n",
      "\tcross_entropy:\n",
      "\t\ttotal = 0.215\n",
      "\t\ttype = 0.126\n",
      "\t\tmode = 0.136\n",
      "\t\tview = 0.750\n",
      "\tmetrics (type):\n",
      "\t\troc_auc = 0.725\n",
      "\t\taverage_precision = 0.939\n",
      "\t\taccuracy = 0.790\n",
      "\t\tsensitivity = 0.853\n",
      "\t\tspecificity = 0.403\n",
      "----------------------------------------\n",
      "Epoch 2 of 12:\n",
      "Training:                                                                                           \n",
      "\tcross_entropy:\n",
      "\t\ttotal = 0.210\n",
      "\t\ttype = 0.114\n",
      "\t\tmode = 0.252\n",
      "\t\tview = 0.708\n",
      "Test:\n",
      "\tcross_entropy:\n",
      "\t\ttotal = 0.193\n",
      "\t\ttype = 0.106\n",
      "\t\tmode = 0.130\n",
      "\t\tview = 0.744\n",
      "\tmetrics (type):\n",
      "\t\troc_auc = 0.723\n",
      "\t\taverage_precision = 0.940\n",
      "\t\taccuracy = 0.837\n",
      "\t\tsensitivity = 0.939\n",
      "\t\tspecificity = 0.212\n",
      "----------------------------------------\n",
      "Epoch 3 of 12:\n",
      "Unfreezing model encoder.\n",
      "Training:                                                                                           \n",
      "\tcross_entropy:\n",
      "\t\ttotal = 0.190\n",
      "\t\ttype = 0.104\n",
      "\t\tmode = 0.181\n",
      "\t\tview = 0.673\n",
      "Test:\n",
      "\tcross_entropy:\n",
      "\t\ttotal = 0.189\n",
      "\t\ttype = 0.113\n",
      "\t\tmode = 0.069\n",
      "\t\tview = 0.695\n",
      "\tmetrics (type):\n",
      "\t\troc_auc = 0.755\n",
      "\t\taverage_precision = 0.952\n",
      "\t\taccuracy = 0.794\n",
      "\t\tsensitivity = 0.860\n",
      "\t\tspecificity = 0.392\n",
      "----------------------------------------\n",
      "Epoch 4 of 12:\n",
      "Training:                                                                                           \n",
      "\tcross_entropy:\n",
      "\t\ttotal = 0.168\n",
      "\t\ttype = 0.092\n",
      "\t\tmode = 0.136\n",
      "\t\tview = 0.630\n",
      "Test:\n",
      "\tcross_entropy:\n",
      "\t\ttotal = 0.195\n",
      "\t\ttype = 0.122\n",
      "\t\tmode = 0.064\n",
      "\t\tview = 0.674\n",
      "\tmetrics (type):\n",
      "\t\troc_auc = 0.739\n",
      "\t\taverage_precision = 0.949\n",
      "\t\taccuracy = 0.768\n",
      "\t\tsensitivity = 0.832\n",
      "\t\tspecificity = 0.379\n",
      "----------------------------------------\n",
      "Epoch 5 of 12:\n",
      "Training:                                                                                           \n",
      "\tcross_entropy:\n",
      "\t\ttotal = 0.152\n",
      "\t\ttype = 0.080\n",
      "\t\tmode = 0.119\n",
      "\t\tview = 0.601\n",
      "Test:\n",
      "\tcross_entropy:\n",
      "\t\ttotal = 0.189\n",
      "\t\ttype = 0.117\n",
      "\t\tmode = 0.061\n",
      "\t\tview = 0.661\n",
      "\tmetrics (type):\n",
      "\t\troc_auc = 0.735\n",
      "\t\taverage_precision = 0.949\n",
      "\t\taccuracy = 0.786\n",
      "\t\tsensitivity = 0.866\n",
      "\t\tspecificity = 0.293\n",
      "----------------------------------------\n",
      "Epoch 6 of 12:\n",
      "Training:                                                                                           \n",
      "\tcross_entropy:\n",
      "\t\ttotal = 0.140\n",
      "\t\ttype = 0.071\n",
      "\t\tmode = 0.111\n",
      "\t\tview = 0.578\n",
      "Test:\n",
      "\tcross_entropy:\n",
      "\t\ttotal = 0.198\n",
      "\t\ttype = 0.127\n",
      "\t\tmode = 0.063\n",
      "\t\tview = 0.651\n",
      "\tmetrics (type):\n",
      "\t\troc_auc = 0.752\n",
      "\t\taverage_precision = 0.952\n",
      "\t\taccuracy = 0.773\n",
      "\t\tsensitivity = 0.835\n",
      "\t\tspecificity = 0.392\n",
      "----------------------------------------\n",
      "Epoch 7 of 12:\n",
      "Training:                                                                                           \n",
      "\tcross_entropy:\n",
      "\t\ttotal = 0.130\n",
      "\t\ttype = 0.064\n",
      "\t\tmode = 0.102\n",
      "\t\tview = 0.561\n",
      "Test:\n",
      "\tcross_entropy:\n",
      "\t\ttotal = 0.209\n",
      "\t\ttype = 0.138\n",
      "\t\tmode = 0.065\n",
      "\t\tview = 0.648\n",
      "\tmetrics (type):\n",
      "\t\troc_auc = 0.744\n",
      "\t\taverage_precision = 0.950\n",
      "\t\taccuracy = 0.768\n",
      "\t\tsensitivity = 0.830\n",
      "\t\tspecificity = 0.391\n",
      "----------------------------------------\n",
      "Epoch 8 of 12:\n",
      "Training:                                                                                           \n",
      "\tcross_entropy:\n",
      "\t\ttotal = 0.121\n",
      "\t\ttype = 0.057\n",
      "\t\tmode = 0.096\n",
      "\t\tview = 0.547\n",
      "Test:\n",
      "\tcross_entropy:\n",
      "\t\ttotal = 0.218\n",
      "\t\ttype = 0.147\n",
      "\t\tmode = 0.067\n",
      "\t\tview = 0.641\n",
      "\tmetrics (type):\n",
      "\t\troc_auc = 0.759\n",
      "\t\taverage_precision = 0.954\n",
      "\t\taccuracy = 0.760\n",
      "\t\tsensitivity = 0.807\n",
      "\t\tspecificity = 0.473\n",
      "----------------------------------------\n",
      "Epoch 9 of 12:\n",
      "Training:                                                                                           \n",
      "\tcross_entropy:\n",
      "\t\ttotal = 0.114\n",
      "\t\ttype = 0.051\n",
      "\t\tmode = 0.094\n",
      "\t\tview = 0.533\n",
      "Test:\n",
      "\tcross_entropy:\n",
      "\t\ttotal = 0.229\n",
      "\t\ttype = 0.158\n",
      "\t\tmode = 0.068\n",
      "\t\tview = 0.640\n",
      "\tmetrics (type):\n",
      "\t\troc_auc = 0.761\n",
      "\t\taverage_precision = 0.954\n",
      "\t\taccuracy = 0.757\n",
      "\t\tsensitivity = 0.796\n",
      "\t\tspecificity = 0.520\n",
      "----------------------------------------\n",
      "Epoch 10 of 12:\n",
      "Training:                                                                                           \n",
      "\tcross_entropy:\n",
      "\t\ttotal = 0.107\n",
      "\t\ttype = 0.046\n",
      "\t\tmode = 0.090\n",
      "\t\tview = 0.522\n",
      "Test:\n",
      "\tcross_entropy:\n",
      "\t\ttotal = 0.246\n",
      "\t\ttype = 0.175\n",
      "\t\tmode = 0.070\n",
      "\t\tview = 0.636\n",
      "\tmetrics (type):\n",
      "\t\troc_auc = 0.766\n",
      "\t\taverage_precision = 0.955\n",
      "\t\taccuracy = 0.747\n",
      "\t\tsensitivity = 0.775\n",
      "\t\tspecificity = 0.577\n",
      "----------------------------------------\n",
      "Epoch 11 of 12:\n",
      "\tBatch 299 of 553. Loss=0.103\r"
     ]
    }
   ],
   "source": [
    "# fit\n",
    "optimizer = optim.AdamP(clf.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "scheduler = ExponentialLR(optimizer, gamma=lr_gamma)\n",
    "\n",
    "train_loss_ls = []\n",
    "test_loss_ls = []\n",
    "metrics_ls = []\n",
    "\n",
    "best_test_loss = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"-\"*40)\n",
    "    print(f\"Epoch {epoch+1} of {num_epochs}:\")\n",
    "\n",
    "    # maybe unfreeze \n",
    "    if epoch >= unfreeze_after_n and is_encoder_frozen:\n",
    "        print(\"Unfreezing model encoder.\")\n",
    "        is_encoder_frozen=False\n",
    "        for p in clf.encoder.parameters():\n",
    "            p.requires_grad = True\n",
    "            \n",
    "        for g in optimizer.param_groups:\n",
    "            g['lr'] = lr_unfrozen\n",
    "\n",
    "\n",
    "    # train for a single epoch\n",
    "    train_loss = train_one_epoch(clf, dl_train, loss_func, device)\n",
    "    train_loss_ls.append(train_loss)\n",
    "    print(f\"Training:\")\n",
    "    print(\"\\tcross_entropy:\")\n",
    "    for k, v in train_loss.items():\n",
    "          print(f\"\\t\\t{k} = {v:0.3f}\") \n",
    "\n",
    "    # evaluate\n",
    "    test_loss, metrics = evaluate(clf, dl_test, loss_func, device)\n",
    "    test_loss_ls.append(test_loss)\n",
    "    # metrics_ls.append(metrics)\n",
    "    print(f\"Test:\")\n",
    "    print(\"\\tcross_entropy:\")\n",
    "    for k, v in test_loss.items():\n",
    "          print(f\"\\t\\t{k} = {v:0.3f}\")\n",
    "    print(f\"\\tmetrics (type):\")\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"\\t\\t{k} = {v:0.3f}\")\n",
    "\n",
    "    # select models with the best type loss\n",
    "    if test_loss['type'] < best_test_loss:\n",
    "        torch.save(clf.state_dict(), f\"{artifact_folder}/model_checkpoint.ckpt\")\n",
    "        best_test_loss = test_loss['type']\n",
    "        \n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deebf54a-5b6a-441f-a177-ca536219005d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PDA",
   "language": "python",
   "name": "pda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
