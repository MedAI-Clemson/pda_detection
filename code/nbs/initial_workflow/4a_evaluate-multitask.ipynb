{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daaa341c-0948-46ae-8454-8e47c62cf06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db27084b-c3c0-4e7a-bc00-dab2262def34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import timm\n",
    "from timm import optim, scheduler\n",
    "import torch\n",
    "from torchvision import transforms as tfm\n",
    "from sklearn import metrics as skmet\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import transforms as my_transforms\n",
    "\n",
    "%aimport dataset\n",
    "from models import MultiTaskFrameClassifier\n",
    "ImageData = dataset.ImageData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7af05b89-c3b2-4d84-8f4a-ab907f26fe8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact_folder = '/zfs/wficai/pda/model_run_artifacts/20220818_multitask_224x224'\n",
    "\n",
    "with open(artifact_folder + '/config.json', 'r') as f: \n",
    "    cfg = json.load(f)\n",
    "\n",
    "# put all config variables in scope to avoid the need to laboriously index cfg\n",
    "for k, v in cfg.items():\n",
    "    v = f\"'{v}'\" if type(v)==str else v\n",
    "    exec(f\"{k}={v}\")\n",
    "del cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a8168f5-8efb-4cb6-a39f-a31dc61f6414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optionally override settings\n",
    "view_filter = ['pdaView', 'pdaRelatedView', 'nonPDAView']\n",
    "mode_filter = ['2d', 'color', 'color_compare']\n",
    "device = torch.device('cuda:1')  # you may need 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c46042a3-6018-4497-ae4a-a40317232777",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = my_transforms.ImageTransforms(res)\n",
    "tfms_test = tfms.get_transforms(transforms['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bd114bb-8654-42da-875d-0bb19d74fb79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of frames after filtering: 44961\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv(f'{artifact_folder}/{out_paths[\"test\"]}')\n",
    "d_test = ImageData(df_test, transforms = tfms_test, mode_filter = mode_filter, view_filter = view_filter)\n",
    "dl_test = DataLoader(d_test, batch_size=bs_test, num_workers=num_workers)\n",
    "\n",
    "print(\"Number of frames after filtering:\", len(d_test.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30c043c1-975b-4d85-9c5a-a1eb7ccb545a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 90\r"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "encoder = timm.create_model(model, pretrained=pretrained, num_classes=1, in_chans=3, drop_rate=dropout)\n",
    "clf = MultiTaskFrameClassifier(encoder).to(device)    \n",
    "clf.load_state_dict(torch.load(f\"{artifact_folder}/model_checkpoint.ckpt\"))\n",
    "clf.eval()\n",
    "loss_function = MultiTaskFrameClassifier.multi_task_loss\n",
    "\n",
    "target_ls = []\n",
    "output_ls = []\n",
    "study_ls = []\n",
    "video_ls = []\n",
    "view_ls = []\n",
    "mode_ls = []\n",
    "losses = []\n",
    "\n",
    "for ix, batch in enumerate(dl_test):\n",
    "    print(f\"Batch {ix+1}\", end = \"\\r\")\n",
    "    inputs = batch['img'].to(device)\n",
    "    targets = {k: batch[k].to(device).type(torch.float32) for k in ['trg_type', 'trg_mode', 'trg_view']}\n",
    "    \n",
    "    target_ls.append(batch['trg_type'].numpy())\n",
    "    view_ls.append(batch['trg_view'].numpy())\n",
    "    mode_ls.append(batch['trg_mode'].numpy())\n",
    "    study_ls += batch['study']\n",
    "    video_ls += batch['video']\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = clf(inputs)\n",
    "        output_ls.append(outputs)\n",
    "        loss = loss_function(outputs, targets, weights)\n",
    "        losses.append(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecef31e9-26a4-48b2-8899-1fefc0cdfe73",
   "metadata": {},
   "source": [
    "# Compute Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d0192d3-c53f-4e8e-bf7b-656a2270813c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(y_true, y_pred, thresh=0.5):\n",
    "    mets = dict()\n",
    "    is_multiclass = (len(y_pred.shape)==2) & (y_pred.shape[-1]>1)\n",
    "    \n",
    "    if not is_multiclass:\n",
    "        y_pred_cls = (y_pred>thresh).astype(int)\n",
    "    else:\n",
    "        y_pred_cls = np.argmax(y_pred, axis=-1)\n",
    "    \n",
    "    mets['num_samples'] = len(y_true)\n",
    "    mets['roc_auc'] = skmet.roc_auc_score(y_true, y_pred, multi_class='ovr')\n",
    "    mets['accuracy'] = skmet.accuracy_score(y_true, y_pred_cls)\n",
    "    mets['sensitivity'] = skmet.recall_score(y_true, y_pred_cls, average='micro')\n",
    "    \n",
    "    if not is_multiclass:\n",
    "        mets['specificity'] = skmet.recall_score(y_true, y_pred_cls, pos_label=0)\n",
    "    \n",
    "    return mets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90ec32c1-f2f8-4e8c-ab27-21532fc1fda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_type = np.concatenate([out['type'].cpu().squeeze() for out in output_ls])\n",
    "pred_type = 1/(1+np.exp(-pred_type))\n",
    "trg_type = np.concatenate([trg.squeeze() for trg in target_ls])\n",
    "\n",
    "pred_view = np.concatenate([out['view'].cpu().squeeze() for out in output_ls])\n",
    "pred_view = np.exp(pred_view) / np.exp(pred_view).sum(axis=-1, keepdims=True)\n",
    "trg_view = np.concatenate([trg.squeeze() for trg in view_ls])\n",
    "\n",
    "pred_mode = np.concatenate([out['mode'].cpu().squeeze() for out in output_ls])\n",
    "pred_mode = np.exp(pred_mode) / np.exp(pred_mode).sum(axis=-1, keepdims=True)\n",
    "trg_mode = np.concatenate([trg.squeeze() for trg in mode_ls])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7693d176-8135-4240-9a0c-32e53e543752",
   "metadata": {},
   "source": [
    "### PDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2bb0ec3d-47c1-4fc4-8d4d-42aa316a7d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>pred</th>\n",
       "      <th>video</th>\n",
       "      <th>mode</th>\n",
       "      <th>view</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.372010</td>\n",
       "      <td>study37_dicom89</td>\n",
       "      <td>color</td>\n",
       "      <td>pdaRelatedView</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.164154</td>\n",
       "      <td>study37_dicom89</td>\n",
       "      <td>color</td>\n",
       "      <td>pdaRelatedView</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.160626</td>\n",
       "      <td>study37_dicom89</td>\n",
       "      <td>color</td>\n",
       "      <td>pdaRelatedView</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.743612</td>\n",
       "      <td>study37_dicom89</td>\n",
       "      <td>color</td>\n",
       "      <td>pdaRelatedView</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.104012</td>\n",
       "      <td>study37_dicom89</td>\n",
       "      <td>color</td>\n",
       "      <td>pdaRelatedView</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type      pred            video   mode            view\n",
       "0     0  0.372010  study37_dicom89  color  pdaRelatedView\n",
       "1     0  0.164154  study37_dicom89  color  pdaRelatedView\n",
       "2     0  0.160626  study37_dicom89  color  pdaRelatedView\n",
       "3     0  0.743612  study37_dicom89  color  pdaRelatedView\n",
       "4     0  0.104012  study37_dicom89  color  pdaRelatedView"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pda = pd.DataFrame({'type': trg_type, 'pred': pred_type, 'video': video_ls, 'mode': trg_mode, 'view': trg_view})\n",
    "df_pda_unmapped = df_pda.copy()\n",
    "df_pda['mode'] = df_pda['mode'].map(ImageData.inv_mode_map)\n",
    "df_pda['view'] = df_pda['view'].map(ImageData.inv_view_map)\n",
    "df_pda.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f181133e-15b9-4173-bbab-60615217123c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame-level scores:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'num_samples': 44961,\n",
       " 'roc_auc': 0.7078433334050096,\n",
       " 'accuracy': 0.6567024754787483,\n",
       " 'sensitivity': 0.6567024754787483,\n",
       " 'specificity': 0.7392204857842214}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"frame-level scores:\")\n",
    "compute_metrics(df_pda['type'], df_pda['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f7e8e3e-4657-4f0f-8a19-80474cf2ca58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>num_samples</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>specificity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>view</th>\n",
       "      <th>mode</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">nonPDAView</th>\n",
       "      <th>2d</th>\n",
       "      <td>11631</td>\n",
       "      <td>0.701040</td>\n",
       "      <td>0.638380</td>\n",
       "      <td>0.638380</td>\n",
       "      <td>0.944585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>color</th>\n",
       "      <td>12073</td>\n",
       "      <td>0.683470</td>\n",
       "      <td>0.631078</td>\n",
       "      <td>0.631078</td>\n",
       "      <td>0.589045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>color_compare</th>\n",
       "      <td>6800</td>\n",
       "      <td>0.867283</td>\n",
       "      <td>0.680147</td>\n",
       "      <td>0.680147</td>\n",
       "      <td>0.641061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">pdaRelatedView</th>\n",
       "      <th>2d</th>\n",
       "      <td>3107</td>\n",
       "      <td>0.776489</td>\n",
       "      <td>0.516897</td>\n",
       "      <td>0.516897</td>\n",
       "      <td>0.989407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>color</th>\n",
       "      <td>2250</td>\n",
       "      <td>0.935112</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.722500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>color_compare</th>\n",
       "      <td>2091</td>\n",
       "      <td>0.865418</td>\n",
       "      <td>0.687709</td>\n",
       "      <td>0.687709</td>\n",
       "      <td>0.558140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">pdaView</th>\n",
       "      <th>2d</th>\n",
       "      <td>1643</td>\n",
       "      <td>0.672757</td>\n",
       "      <td>0.468655</td>\n",
       "      <td>0.468655</td>\n",
       "      <td>0.991379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>color</th>\n",
       "      <td>1374</td>\n",
       "      <td>0.912451</td>\n",
       "      <td>0.808588</td>\n",
       "      <td>0.808588</td>\n",
       "      <td>0.598326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>color_compare</th>\n",
       "      <td>3992</td>\n",
       "      <td>0.871356</td>\n",
       "      <td>0.772044</td>\n",
       "      <td>0.772044</td>\n",
       "      <td>0.701433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              num_samples   roc_auc  accuracy  sensitivity  \\\n",
       "view           mode                                                          \n",
       "nonPDAView     2d                   11631  0.701040  0.638380     0.638380   \n",
       "               color                12073  0.683470  0.631078     0.631078   \n",
       "               color_compare         6800  0.867283  0.680147     0.680147   \n",
       "pdaRelatedView 2d                    3107  0.776489  0.516897     0.516897   \n",
       "               color                 2250  0.935112  0.822222     0.822222   \n",
       "               color_compare         2091  0.865418  0.687709     0.687709   \n",
       "pdaView        2d                    1643  0.672757  0.468655     0.468655   \n",
       "               color                 1374  0.912451  0.808588     0.808588   \n",
       "               color_compare         3992  0.871356  0.772044     0.772044   \n",
       "\n",
       "                              specificity  \n",
       "view           mode                        \n",
       "nonPDAView     2d                0.944585  \n",
       "               color             0.589045  \n",
       "               color_compare     0.641061  \n",
       "pdaRelatedView 2d                0.989407  \n",
       "               color             0.722500  \n",
       "               color_compare     0.558140  \n",
       "pdaView        2d                0.991379  \n",
       "               color             0.598326  \n",
       "               color_compare     0.701433  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_results = df_pda.groupby(['view', 'mode']).apply(lambda x: compute_metrics(x['type'], x['pred']))\n",
    "grouped_results = pd.DataFrame(grouped_results.tolist(), index=grouped_results.index)\n",
    "grouped_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd22103d-1921-452c-8fd9-760a78be6381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video-level-scores\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'num_samples': 478,\n",
       " 'roc_auc': 0.7195093810462041,\n",
       " 'accuracy': 0.6694560669456067,\n",
       " 'sensitivity': 0.6694560669456067,\n",
       " 'specificity': 0.7715355805243446}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('video-level-scores')\n",
    "df_pda_vid = df_pda.groupby(['type', 'video', 'mode', 'view'], as_index=False).agg('mean')\n",
    "compute_metrics(df_pda_vid['type'], df_pda_vid['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0fcc4866-f33b-4a2c-a6b7-b044f969747e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>num_samples</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>specificity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>view</th>\n",
       "      <th>mode</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">nonPDAView</th>\n",
       "      <th>2d</th>\n",
       "      <td>139</td>\n",
       "      <td>0.743721</td>\n",
       "      <td>0.611511</td>\n",
       "      <td>0.611511</td>\n",
       "      <td>0.975309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>color</th>\n",
       "      <td>128</td>\n",
       "      <td>0.718988</td>\n",
       "      <td>0.632812</td>\n",
       "      <td>0.632812</td>\n",
       "      <td>0.492754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>color_compare</th>\n",
       "      <td>57</td>\n",
       "      <td>0.951389</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.729167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">pdaRelatedView</th>\n",
       "      <th>2d</th>\n",
       "      <td>36</td>\n",
       "      <td>0.868750</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>color</th>\n",
       "      <td>28</td>\n",
       "      <td>0.964103</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>color_compare</th>\n",
       "      <td>20</td>\n",
       "      <td>0.947917</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">pdaView</th>\n",
       "      <th>2d</th>\n",
       "      <td>19</td>\n",
       "      <td>0.726190</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>color</th>\n",
       "      <td>17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>color_compare</th>\n",
       "      <td>34</td>\n",
       "      <td>0.917857</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              num_samples   roc_auc  accuracy  sensitivity  \\\n",
       "view           mode                                                          \n",
       "nonPDAView     2d                     139  0.743721  0.611511     0.611511   \n",
       "               color                  128  0.718988  0.632812     0.632812   \n",
       "               color_compare           57  0.951389  0.754386     0.754386   \n",
       "pdaRelatedView 2d                      36  0.868750  0.500000     0.500000   \n",
       "               color                   28  0.964103  0.892857     0.892857   \n",
       "               color_compare           20  0.947917  0.750000     0.750000   \n",
       "pdaView        2d                      19  0.726190  0.368421     0.368421   \n",
       "               color                   17  1.000000  1.000000     1.000000   \n",
       "               color_compare           34  0.917857  0.852941     0.852941   \n",
       "\n",
       "                              specificity  \n",
       "view           mode                        \n",
       "nonPDAView     2d                0.975309  \n",
       "               color             0.492754  \n",
       "               color_compare     0.729167  \n",
       "pdaRelatedView 2d                1.000000  \n",
       "               color             0.800000  \n",
       "               color_compare     0.583333  \n",
       "pdaView        2d                1.000000  \n",
       "               color             1.000000  \n",
       "               color_compare     0.785714  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_results = df_pda_vid.groupby(['view', 'mode']).apply(lambda x: compute_metrics(x['type'], x['pred']))\n",
    "grouped_results = pd.DataFrame(grouped_results.tolist(), index=grouped_results.index)\n",
    "grouped_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "817265f9-c0e2-45cb-bebe-3cad879de611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_samples': 99,\n",
       " 'roc_auc': 0.9454470877768664,\n",
       " 'accuracy': 0.8686868686868687,\n",
       " 'sensitivity': 0.8686868686868687,\n",
       " 'specificity': 0.7608695652173914}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pda_vid_goodviews = df_pda_vid.query('mode!=\"2d\" and view!=\"nonPDAView\"')\n",
    "compute_metrics(df_pda_vid_goodviews['type'], df_pda_vid_goodviews['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72a76d09-4d6c-4bde-b82c-5e1da651cdbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View prediction\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'num_samples': 44961,\n",
       " 'roc_auc': 0.8871884989028015,\n",
       " 'accuracy': 0.7831453926736505,\n",
       " 'sensitivity': 0.7831453926736505}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"View prediction\")\n",
    "compute_metrics(trg_view, pred_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49219cd4-014b-4e45-800d-4fb24b6f9b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          nonPDAView\n",
       "1          nonPDAView\n",
       "2          nonPDAView\n",
       "3      pdaRelatedView\n",
       "4      pdaRelatedView\n",
       "            ...      \n",
       "473        nonPDAView\n",
       "474        nonPDAView\n",
       "475        nonPDAView\n",
       "476    pdaRelatedView\n",
       "477        nonPDAView\n",
       "Name: view, Length: 478, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pda_vid.view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e73bbe6-9da3-42ee-a8f7-da4681a1c64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode prediction\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'num_samples': 44961,\n",
       " 'roc_auc': 0.9929284210019661,\n",
       " 'accuracy': 0.9867218255821713,\n",
       " 'sensitivity': 0.9867218255821713}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Mode prediction\")\n",
    "compute_metrics(trg_mode, pred_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f334d7-72ad-4f97-9d27-6c756ec7f607",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PDA",
   "language": "python",
   "name": "pda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
